# Agentic Reasoning

ref
- [YouTube](https://www.youtube.com/watch?v=sal78ACtGTc)
- [中文原文_知乎](https://zhuanlan.zhihu.com/p/690034176)

## 正文

我非常期待向大家展示我对AI智能体 (AI Agent) 的看法，这是一个令人激动的趋势，我认为每个AI开发者都应该重视。同时，我也对接下来的其他演讲充满期待。


在当今时代，我们使用大语言模型 (Large Language Model) 的方式往往非常直接（Non-agentic workflow）——提出 prompt 并得到答案，就像是让一个人不停地写作，从一开始到结束都不许使用退格键一样。尽管这样的任务非常困难，但大语言模型表现得出奇地好。然而，一种智能体的工作流程情况可能会大不相同：先是让 AI/LM 草拟一个大纲，思考是否需要进行联网搜索，如果需要就搜索，然后先撰写初稿，接着是自我审阅初稿，思考哪些部分需要修改，进而进行修订。这个过程是迭代的，可能需要多次思考和修改才能完善。很少有人知道，这种方式能够显著提高成果的质量。我在使用这些智能体工作流时，真的对它们的效果感到非常吃惊。

在一个案例研究中，我们的团队利用了OpenAI几年前发布的一个编程基准测试——Human Eval基准测试，对一些数据进行了分析。这个测试包含了一些编程题目：例如，给定一个非空的整数列表，求所有奇数元素或奇数位置上元素的总和。结果可能是一段这样的代码。


现在，我们很多人采用零样本（Zero-shot）提示的方式来指导AI编程，也就是说，我们让AI直接写出代码，并期望它能一次性正确运行。但是，真的有人这样编码吗？没有人会这样写代码，我们通常是边写边运行代码，或许有人能做到一次性就写对，但我做不到。结果显示，使用GPT-3.5进行零样本提示的情况下，其正确率为48%。而GPT-4的表现则好得多，正确率达到了67%。

但是，当你将代理式工作流程结合到GPT-3.5中时，比方说，它的表现甚至超过了GPT-4。同样，如果你把这种工作流程应用到GPT-4上，你会发现它同样能够取得更出色的成绩。这里有一个值得注意的现象：采用智能体式工作流程的GPT-3.5在性能上实际上超过了GPT-4。我认为，这一发现对我们构建应用程序的方法产生了重大影响。


也因此，“智能体”成为了一个广泛讨论的话题。市场上有大量的咨询报告，讨论智能体以及AI的未来等等。但我想具体点，跟大家分享我观察到的智能体设计中的一些常见模式。这是一个复杂且充满挑战的领域，充斥着海量的研究成果和开源项目，有很多正在进行的工作。我尝试对它们进行了一些具体的分类。

反思（Reflection）是一项我认为我们都应该利用的技术，确实很有效。工具使用（Tool use）应用更广泛，我认为，这是一种非常可靠的技术。基于我的经验，使用这些技术时，我几乎总能够达到良好的效果。至于规划（Planning）和多智能体协作（Multi-Agent collaboration），我觉得这还是一个新兴领域。使用这些技术时，它们有时候的表现令我震惊，但至少就目前来说，我认为它们的可靠性还有待提高。接下来，我将详细介绍这些设计模式。如果你能回去并鼓励你的工程师团队采纳这些建议，我相信你们会很快看到生产力的显著提升。


反思
关于反思的能力，这里有一个典型的例子。设想我们请求一个系统根据给定的任务为我们编写代码，然后我们有一个编程智能体——我们通过提出 prompt 来编写特定代码的 LLM，例如定义一个函数def do_task。一个自我反思的例子可能是，之后我们使用这样的 prompt 来引导LLM：“这是为某个任务编写的代码”，并将它刚刚生成的完全相同的代码展示给它，接着指示它：“请仔细检查代码的正确性、运行效率以及结构良好。”仅通过这样的prompt。结果是，原先写代码的同一个LM可能会发现诸如第5行的bug，并可能提出修复方法。如果你现在将它的反馈再次输入给它，并重新进行prompt，它可能会生成一个改进后的版本，这个新版本很可能比原来的版本运行得更好。虽然不能绝对保证，但这种方法经常有效，值得在许多应用中尝试。


如果同时考虑工具使用，特别是在进行单元测试的情况下。如果代码没有通过某个单元测试，你可以询问它为什么没有通过单元测试，通过对话让它尝试进行一些修改，并进而编写出第三版代码。

顺便说一下，对于那些想深入了解这些技术的人来说，我对此非常激动。每个部分的底部我都准备了一小节推荐阅读材料，希望能提供更多的参考。

我之前描述的多智能体系统，实际上是关于如何引导一个编码智能体与自身进行交流的过程。这个概念的一个自然扩展是，与其使用单一的编程智能体，不如尝试配对两个智能体——一个作为编码者，另一个作为评审者。这两个智能体可以基于同一个大语言模型，但分别以不同的 prompt 进行引导。我们可以告诉第一个智能体：“你是一个编码专家，请编写代码。”而对第二个智能体则说：“你是代码审查的专家，请审查这段代码。”仅需这样一个工作流程，就能实现。我认为，这是一种非常适用于各种工作流程的通用技术，实施起来实际上非常简单。这种方法将极大地提升大语言模型的表现。


工具使用
第二种设计模式涉及到许多人已经熟悉的，即基于LLM的系统利用各种工具来增强功能。


例如，屏幕左侧展示的是Copilot的界面截图，而右侧则是我从GPT-4中提取的一个示例。如今，当你询问LLM诸如“网上最好的咖啡机是什么？”这样的问题，或者生成并执行代码，这表明许多不同的工具被广泛用于分析、信息收集、采取行动以及提升个人生产力。有趣的是，很多关于工具的早期研究实际上是在计算机视觉（CV）领域完成的，因为在大语言模型兴起之前，LLM无法处理图像数据。因此，如果LLM生成的函数调用能够操作图像——无论是生成图像、进行对象检测等——那就成为了唯一的选择。如果仔细研究相关文献，你会发现，许多工具相关的创新似乎都起源于视觉领域，这是因为在GPT-4V和LLaVA等技术出现之前，LLM对于图像几乎是“盲目”的。工具的使用大大拓宽了LLM的应用范围。

规划
接着是规划——对于那些尚未深入探索规划算法的人来说，许多人都被ChatGPT带来的震撼所吸引，对其前所未见的能力感到惊叹。如果你还没尝试过基于规划的LLM，你可能会对AI智能体的能力感到震惊，认为它们做到了你认为不可能的事。我做过的一些实时演示显示，即使在出现故障时，AI智能体也能重新规划路径来绕过失败。其实我也好多次都不敢相信自己的AI系统能够如此自主地完成任务。


比如我从HuggingGPT论文中改变的一个例子，你可以请求生成一张女孩读书的图片，要求她的姿势与某个示例图片中的男孩相同，然后用语音来描述这张新图片。利用当前的AI智能体，首先需要确定男孩的姿势，然后在HuggingFace找到合适的模型来提取这一姿势。随后需要找到一个可以根据指令合成女孩姿势图片的模型，接着利用图像转文本技术，最后应用文本转语音技术完成描述。我们现在拥有一些智能体，虽然它们并不总是可靠，有时表现可能有些繁琐，但当它们正常工作时，成果确实令人惊叹。

通过智能体式的反馈循环，有时候我们甚至可以从之前的失败中找到思路。我已经开始在一些工作中运用研究型AI智能体了，比如当我需要一些研究资料却不想自己亲自上网搜寻时，我只需把任务交给研究智能体，几分钟后回来看看它找到了什么。这种方法有时有效，有时不行，但它已经成为我的个人工作流程的一部分了。

多智能体协作
最后介绍的设计模式是多智能体协作。这是一个非常有趣的概念，而且它的效果远比你想象的要好。比如ChatDev的案例，它是一个完全开源的项目。你可能已经在社交媒体上看到过它的一些demo。它可以在我的笔记本电脑上运行，ChatDev展示了一个多智能体系统的典型应用，你可以引导一个LLM在不同情境下扮演不同角色，比如软件工程公司的CEO、设计师、产品经理或测试员等不同角色，通过向LLM发出指令让他们扮演这些角色，这些智能体就会开始协作，并进行深入的对话。例如，如果你要求它们开发一个“GoMoki”游戏，它们实际上能够花上几分钟来编写代码、进行测试、迭代，并最终生成复杂程度远超预期的程序。虽然它们不总是按预期工作，但当它们有效时，其结果令人震撼，这项技术正处于持续进步之中。


另一种设计模式则是多智能体辩论，当你让不同的AI智能体，比如ChatGPT和Gemini进行互相辩论，这种方法事实上也能显著提高性能。所以让多个AI智能体协同工作已经被证实是一个强大的设计模式。

简而言之，我观察到的这些模式显示，如果我们能将这些设计模式应用到我们的工作中，很多人都能迅速提高生产力。我认为，智能体推理的设计模式将是一个重要的发展方向。


我预计由于智能体式工作流的引入，AI能完成的任务种类预计将在今年大幅增加。

然而，人们通常期待AI智能体能立即响应，这是一个需要逐渐适应的挑战。实际上，十年前我在Google参与的一个“big box”搜索的项目中，我们输入了很长的prompt，当初没能推动这项研究的原因之一就是，在搜索时，我们希望迅速得到所需信息，这种即时满足感是人类的本性。但对于智能体工作流，我们也许需要学会把任务交给智能体去执行，需要学会耐心等待可能是几分钟，甚至几小时才能获得回应。这与许多新手管理者的行为相反，他们倾向于分派任务后不久就急于了解进展，这实际上并不利于提高效率。我认为我们也需要对一些AI智能体这样做，尽管存在困难。


另外，快速生成Token是一个重要的趋势。因为在智能体式工作流中，我们需要不断地迭代，LLM为自己生成需要进一步阅读的Token，所以能够远远超过人类阅读速度的Token生成速度是非常令人兴奋的。我认为，即使是质量稍低的LLM快速生成大量Token，相较于从更高质量的LLM中缓慢生成Token，可能也能取得不错的结果。这个观点可能有些争议，因为它意味着你可以更频繁地进行迭代，就像我之前展示的GPT-3和智能体架构的结果一样。

坦白说，我非常期待GPT-5、Claude-4、Gemini-2以及其他新模型。但如果你期待在GPT-5上以零样本运行你的项目，你可能会发现，通过智能体式推理，即使是在早期模型上也能在某些应用上达到接近你想象的性能水平。我认为这是一个重要的发展趋势。

说实话，通向通用人工智能（AGI）的道路感觉就像是一段旅程，而不是一个目的地，但我相信，这些智能体工作流也许能帮助我们在这段漫长的旅途中向前迈出一小步。谢谢。