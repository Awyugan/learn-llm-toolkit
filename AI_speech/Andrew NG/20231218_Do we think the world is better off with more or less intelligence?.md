# Do we think the world is better off with more or less intelligence?

ä¸­æ–‡ç¨¿ğŸ‡¨ğŸ‡³ï¼š[å´æ©è¾¾ï¼šâ€œæˆ‘ä»¬è®¤ä¸ºä¸–ç•Œçš„æ™ºæ…§æ˜¯è¶Šå¤šè¶Šå¥½è¿˜æ˜¯è¶Šå°‘è¶Šå¥½ï¼Ÿâ€](https://mp.weixin.qq.com/s/-KcuXdUMhx0nSn-mjryabg)
è‹±æ–‡ç¨¿[Do we think the world is better off with more or less intelligence?](https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3)

åœ¨ã€Šé‡‘èæ—¶æŠ¥ã€‹è®°è€…Ryan McMorrowé€ è®¿Andrew Ngä½äºç¡…è°·å¸•æ´›é˜¿æ‰˜çš„åŠå…¬å®¤æ—¶ï¼Œä»–æ‹¿å‡ºäº†ä¸€å°æ²¡æœ‰è”ç½‘çš„ç¬”è®°æœ¬ç”µè„‘ï¼Œæ¼”ç¤ºäº†ä¸€ä¸ªæ¥è‡ªæ³•å›½äººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸Mistralçš„å¼€æºå¤§æ¨¡å‹ã€‚è¿è¡Œè¯¥æ¨¡å‹å¯ä»¥ä¸ä¾èµ–äº‘ç«¯ã€‚â€œæ¨¡å‹å°±å­˜å‚¨åœ¨æˆ‘çš„ç¡¬ç›˜ä¸Šï¼Œé€šè¿‡ç¬”è®°æœ¬ä¸Šçš„GPUå’ŒCPUè¿è¡Œâ€Ngè¯´ã€‚

å½“ä½ å‘è¯¥æ¨¡å‹æé—®â€œè®°è€…åº”è¯¥é‡‡è®¿Andrew Ngå“ªäº›äººå·¥æ™ºèƒ½é—®é¢˜â€æ—¶ï¼Œå®ƒä¼šæä¾›å…³äºNgæœ¬äººå’Œä»–çš„å·¥ä½œèƒŒæ™¯ä¿¡æ¯ï¼Œè¿™å’ŒChatGPTçš„å›åº”ç›¸å·®æ— å‡ ã€‚

RMï¼šä½ åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šç”¨è¿™äº›å¼€æºæ¨¡å‹ï¼Ÿ

ANï¼šæˆ‘çš„ç¬”è®°æœ¬ä¸Šè¿è¡Œç€å¤šä¸ªæ¨¡å‹â€”â€”åŒ…æ‹¬Mistralã€LLaMaå’ŒZefaï¼Œæˆ‘ä¹Ÿç»å¸¸ç”¨ChatGPTã€‚ä½†å¯¹äºé‚£äº›æˆ‘ä¸æƒ³ä¸Šä¼ äº‘ç«¯çš„æ•æ„Ÿä¿¡æ¯ï¼Œæˆ‘æ›´å€¾å‘äºåœ¨ç¬”è®°æœ¬ç”µè„‘ä¸Šä½¿ç”¨å®ƒä»¬ã€‚ä¾‹å¦‚ï¼Œæ¶‰åŠé«˜åº¦æœºå¯†é¡¹ç›®çš„æ„æ€ï¼Œæˆ–è€…æˆ‘è¦æ’°å†™çš„å«æ•æ„Ÿè´¢åŠ¡æ•°æ®çš„æ–‡æ¡£ï¼Œæˆ‘ä¼šé€‰æ‹©ä½¿ç”¨å¼€æºæ¨¡å‹ã€‚äº‹å®ä¸Šï¼Œå¼€æºæ¨¡å‹ç°åœ¨çš„è¡¨ç°å·²ç»ç›¸å½“å‡ºè‰²äº†ã€‚

RMï¼šè®¸å¤šç§‘æŠ€å…¬å¸è¿«åˆ‡éœ€è¦NvidiaèŠ¯ç‰‡æ¥è¿è¡Œäººå·¥æ™ºèƒ½ã€‚å¦‚æœä½ ç¬”è®°æœ¬ä¸Šçš„Mistralæ¨¡å‹å¯ä»¥èƒœä»»ä»»åŠ¡ï¼Œé‚£ä¹ˆä»–ä»¬ï¼ˆç§‘æŠ€å…¬å¸ï¼‰ä¸ºä»€ä¹ˆè¿˜è¦è´¹å°½å¿ƒæ€è·å–è¿™äº›èŠ¯ç‰‡å‘¢ï¼Ÿ

ANï¼šMistralæ˜¯ä¸€ä¸ªè§„æ¨¡è¾ƒå°çš„è¯­è¨€æ¨¡å‹ï¼šå®ƒåªæœ‰70äº¿å‚æ•°ï¼Œå¯¹äºå¤æ‚æ¨ç†ä»»åŠ¡æ¥è¯´ï¼Œæ— æ³•ä¸GPT-4ç›¸æå¹¶è®ºã€‚ä½†å¯¹äºç®€å•çš„æ„æ€å’ŒåŸºç¡€äº‹å®ï¼ŒMistralå·²ç»è¶³å¤Ÿäº†ã€‚ä½ ä¹Ÿçœ‹åˆ°äº†ï¼Œå®ƒçš„å“åº”é€Ÿåº¦æœ‰æ—¶éå¸¸å¿«ã€‚

ä¸è¿‡ï¼Œåœ¨æˆ‘ç¬”è®°æœ¬ä¸Šä»é›¶å¼€å§‹è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ˜¯æ ¹æœ¬ä¸å¯èƒ½çš„â€”â€”è¿™éœ€è¦æ•°åƒä¸‡ç¾å…ƒçš„æˆæœ¬ã€å·¨å¤§è®¡ç®—é‡çš„è®­ç»ƒã€åœ¨éå¸¸å¤§çš„æ¨¡å‹ä¸Šè¿›è¡Œæ¨ç†ï¼Œè¿™è¶…å‡ºäº†æˆ‘èƒ½åœ¨ç¬”è®°æœ¬ä¸Šå®Œæˆçš„èŒƒç•´ã€‚

å®é™…ä¸Šï¼Œæˆ‘ä¹Ÿå°è¯•åœ¨ç¬”è®°æœ¬ä¸Šè¿è¡Œä¸€ä¸ª700äº¿å‚æ•°çš„æ¨¡å‹ï¼Œä½†é€Ÿåº¦å®åœ¨å¤ªæ…¢äº†ã€‚å¦‚æœä½ æ‹¿ä¸€ä¸ª1750äº¿å‚æ•°çš„æ¨¡å‹ï¼ˆGPT-3è§„æ¨¡ï¼‰åœ¨æˆ‘çš„ç¬”è®°æœ¬ä¸Šä¹Ÿæ˜¯è¡Œä¸é€šçš„ã€‚å¤§æ¨¡å‹ä¸Šçš„æ¨ç†ä»ç„¶éœ€è¦æ•°æ®ä¸­å¿ƒçº§åˆ«çš„èµ„æºã€‚ç°åœ¨å¼€æºè½¯ä»¶å·²ç»å˜å¾—è¶³å¤Ÿç®€å•ï¼Œå¤§å¤šæ•°äººéƒ½å¯ä»¥è½»æ¾å®‰è£…å’Œä½¿ç”¨ã€‚

æˆ‘å¹¶ä¸æ˜¯æ²‰è¿·ç›‘ç®¡é—®é¢˜â€”â€”ä½†å¦‚æœä¸€äº›ç›‘ç®¡è€…å¦‚æ„¿ä»¥å¿ï¼Œé‚£ä¹ˆè¿™æ ·çš„å¼€æºæ¨¡å‹ä¼šæ›´éš¾æŒç»­æ›´æ–°ã€‚

RMï¼šç›‘ç®¡å¦‚ä½•æ‰°ä¹±å¼€æºæ¨¡å‹ï¼Ÿ

ANï¼šæ¯”å¦‚ä¸€äº›ææ¡ˆè¦æ±‚LLMsæ‹¿åˆ°æŠ¥å‘Šï¼Œç”šè‡³æ˜¯è®¸å¯è¯æ˜ã€‚å¤§å‹ç§‘æŠ€å…¬å¸æœ‰èƒ½åŠ›å¤„ç†è¿™äº›å¤æ‚çš„åˆè§„è¦æ±‚ï¼Œä½†å°å‹ä¼ä¸šåˆ™æ²¡æœ‰è¿™ä¸ªæ¡ä»¶ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œå½“ä¸€ä¸ªä¸­ç­‰è§„æ¨¡çš„å…¬å¸æƒ³å‘å¸ƒä¸€ä¸ªå¼€æºæ¨¡å‹æ—¶ï¼Œå…¬å¸æ³•å¾‹é¡¾é—®ä¼šè¯´ï¼šâ€œå¦‚æœä½ è¿™æ ·åšï¼Œå¯èƒ½ä¼šæœ‰å„ç§æ³•å¾‹é£é™©â€ã€‚é‚£ä¹ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è®¤ä¸ºä¼šæœ‰æ›´å°‘çš„å…¬å¸æ„¿æ„æ‰¿æ‹…è¿™ç§é£é™©ã€‚æ— è®ºæ˜¯å¯¹ä»€ä¹ˆåŠ å¤§ç›‘ç®¡ï¼Œæˆ‘ä»¬éƒ½ä¼šçœ‹åˆ°ç›¸å…³æ¨¡å‹çš„å‡å°‘ã€‚

ä¸€ä¸ªå¼€æºæ¨¡å‹æ˜¯ä¸€ç§é€šç”¨æŠ€æœ¯ï¼šå®ƒå¯ä»¥ç”¨äºæ„å»ºåŒ»ç–—åº”ç”¨ã€å®¢æˆ·æœåŠ¡åº”ç”¨ã€é‡‘èæœåŠ¡åº”ç”¨ç­‰ç­‰ã€‚å› æ­¤ï¼Œå¦‚æœä½ å¯¹å¼€æºæ¨¡å‹è¿™ä¸ªæ ¸å¿ƒæŠ€æœ¯è¿›è¡Œç›‘ç®¡ï¼Œä½ å®é™…ä¸Šæ˜¯åœ¨å‡æ…¢æ‰€æœ‰äº‹ç‰©çš„å‘å±•é€Ÿåº¦ï¼Œè€Œä¸”å¯èƒ½å¹¶æ²¡æœ‰å®è´¨æ€§åœ°æé«˜å®‰å…¨æ€§ã€‚

RMï¼šåœ¨è®¨è®ºç›‘ç®¡çš„æ¡†æ¶æ—¶ï¼Œå¿…é¡»äº†è§£äººå·¥æ™ºèƒ½ç›®å‰çš„èƒ½åŠ›ã€‚ä»Šå¹´6æœˆï¼Œä½ å’ŒHintonè¿›è¡Œäº†ä¸€æ¬¡å¯¹è¯ï¼Œä»–æ›¾è­¦å‘Šè¿‡äººå·¥æ™ºèƒ½çš„å±é™©ã€‚ä½ ä»¬è®¨è®ºäº†äººå·¥æ™ºèƒ½æ¨¡å‹æ˜¯å¦çœŸæ­£ç†è§£ä¸–ç•Œï¼Œå½“æ—¶ä½ ä¼¼ä¹ä¸å®Œå…¨ç›¸ä¿¡å®ƒä»¬èƒ½åšåˆ°ã€‚ç°åœ¨å‘¢ï¼Ÿä½ çš„çœ‹æ³•æ˜¯ï¼Ÿ

ANï¼šæˆ‘è®¤ä¸ºäººå·¥æ™ºèƒ½æ¨¡å‹ç¡®å®æœ‰è¿™ç§èƒ½åŠ›ã€‚é—®é¢˜åœ¨äºï¼Œåƒâ€œç†è§£â€ï¼ˆunderstandsï¼‰è¿™æ ·çš„æœ¯è¯­ï¼Œæˆ–è€…è¯´â€œæ„è¯†â€ï¼ˆconsciousï¼‰ã€â€œçŸ¥è§‰â€ï¼ˆsentientï¼‰æ²¡æœ‰æ˜ç¡®çš„å®šä¹‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ²¡æœ‰ä¸€ä¸ªå…¬è®¤çš„æ ‡å‡†æ¥æµ‹è¯•æŸäº‹ç‰©ä½•æ—¶çœŸåœ°ç†è§£äº†æŸç‰©ï¼Œè€Œä¸æ˜¯ä»…ä»…è¡¨ç°å¾—åƒæ˜¯ç†è§£äº†ã€‚

ä½†æ ¹æ®æˆ‘æ‰€çœ‹åˆ°çš„ç§‘å­¦è¯æ®ï¼Œäººå·¥æ™ºèƒ½æ¨¡å‹ç¡®å®åœ¨æ„å»ºå®ƒä»¬çš„ä¸–ç•Œè§‚ã€‚æ‰€ä»¥ï¼Œå¦‚æœä¸€ä¸ªäººå·¥æ™ºèƒ½æ‹¥æœ‰äº†ä¸€ä¸ªâ€œä¸–ç•Œæ¨¡å‹â€ï¼Œæˆ‘å€¾å‘äºè®¤ä¸ºå®ƒç†è§£äº†ä¸–ç•Œâ€”â€”è¿™æ˜¯åŸºäºæˆ‘ä¸ªäººå¯¹â€œç†è§£â€ï¼ˆunderstandsï¼‰ä¸€è¯çš„è§£é‡Šã€‚

RMï¼šä½ æ‰€è¯´çš„â€œä¸–ç•Œæ¨¡å‹â€æ˜¯ä»€ä¹ˆï¼Ÿ

ANï¼šå¦‚æœä½ æœ‰ä¸€ä¸ªâ€œä¸–ç•Œæ¨¡å‹â€ï¼Œä½ å°±æœ‰äº†å¯¹ä¸–ç•Œè¿ä½œæ–¹å¼çš„ç†è§£ï¼Œè€Œä¸”å¯ä»¥é¢„æµ‹ï¼Œæœªæ¥åœ¨ä¸åŒæƒ…å†µä¸‹ä¼šä½œä½•å‘å±•ã€‚ç§‘å­¦è¯æ®è¡¨æ˜ï¼Œç»è¿‡å¤§é‡æ•°æ®è®­ç»ƒçš„LLMsç¡®å®æ„å»ºäº†ä¸€ä¸ªä¸–ç•Œæ¨¡å‹ã€‚

ç ”ç©¶äººå‘˜è®©ä¸€ä¸ªLLMæ¨¡æ‹Ÿé¢„æµ‹å¥¥èµ›ç½—æ£‹ç›˜æ¸¸æˆçš„ä¸‹ä¸€æ­¥èµ°æ³•â€”â€”C4ã€D5ã€B3ç­‰ç­‰ã€‚ä¹‹åï¼Œä»–ä»¬å†æ¢ç©¶â€œLLMæ˜¯å¦å­¦ä¼šäº†æ£‹ç›˜å¸ƒå±€ï¼Œæ˜¯å¦å­¦ä¼šäº†å¥¥èµ›ç½—æ¸¸æˆçš„è§„åˆ™â€ã€‚ç ”ç©¶äººå‘˜å‘ç°ï¼Œç¥ç»ç½‘ç»œå†…éƒ¨ä¼¼ä¹çœŸçš„æ„å»ºäº†ä¸€ä¸ªå¯ä»¥é¢„æµ‹ä¸‹æ£‹çš„æ£‹ç›˜æ¨¡å‹ã€‚åŸºäºè¿™ä¸ªå®éªŒå’Œå…¶ä»–ç±»ä¼¼å®éªŒï¼Œæˆ‘ç›¸ä¿¡LLMsç¡®å®æ„å»ºäº†æŸç§ä¸–ç•Œæ¨¡å‹ã€‚æˆ‘å¯ä»¥ç”±è¡·åœ°è¯´ï¼Œå®ƒä»¬ç¡®å®ç†è§£äº†ä¸–ç•Œã€‚

RMï¼šä½ è®¤ä¸ºLLMsæœ‰â€œæ„è¯†â€ï¼ˆconsciousï¼‰å—ï¼Ÿ

ANï¼šæˆ‘å¯èƒ½ä¼šå›é¿å…³äºâ€œæ„è¯†â€ï¼ˆconsciousï¼‰çš„é—®é¢˜ã€‚å› ä¸ºå¯¹æˆ‘è€Œè¨€ï¼Œè¿™æ›´åƒæ˜¯ä¸€ä¸ªå“²å­¦é—®é¢˜è€Œä¸æ˜¯ç§‘å­¦é—®é¢˜ã€‚å“²å­¦å®¶è¯´ï¼Œæˆ‘ä»¬å‡è®¾åˆ«äººæ˜¯æœ‰æ„è¯†çš„ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ç§ç¤¼è²Œçš„è¯´æ³•ã€‚å› ä¸ºä½ æ€ä¹ˆçŸ¥é“æˆ‘æœ‰æ„è¯†ï¼Ÿä¹Ÿè®¸æˆ‘åªæ˜¯ä¸€ä¸ªçœ‹èµ·æ¥æœ‰æ„è¯†çš„åƒµå°¸ã€‚å› æ­¤ï¼Œæˆ‘è®¤ä¸ºæ„è¯†æ˜¯æ— æ³•æµ‹è¯•çš„ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒæ˜¯å“²å­¦é—®é¢˜è€Œä¸æ˜¯ç§‘å­¦é—®é¢˜çš„åŸå› ã€‚

RMï¼šæ’‡å¼€â€œæ„è¯†â€ï¼ˆconsciousï¼‰ä¸è°ˆï¼Œä½ è®¤ä¸ºLLMèƒ½å¤Ÿâ€œè‡ªè¡Œæ€è€ƒâ€å—ï¼Ÿ

ANï¼šæˆ‘ä¸æ¸…æ¥šâ€œè‡ªè¡Œæ€è€ƒâ€è¿™ä¸ªè¯çš„ç¡®åˆ‡å«ä¹‰ã€‚æˆ‘å€¾å‘äºæ˜¯çš„ï¼Œä½†ç”±äºç¼ºä¹å¯¹â€œæ€è€ƒâ€ ï¼ˆthinkï¼‰çš„æ˜ç¡®å®šä¹‰ï¼Œè¿™ä¸ªè¯´æ³•å¾ˆéš¾ç«™å¾—ä½è„šã€‚æ¢ä¸ªè¯´æ³•ï¼Œå¸é¡¶ç¯é‡Œçš„ç»§ç”µå™¨å¼€å…³èƒ½å¦â€œè‡ªè¡Œæ€è€ƒâ€ï¼Ÿæˆ‘å€¾å‘äºè®¤ä¸ºå®ƒå¯ä»¥ï¼Œä½†æˆ‘è®¤ä¸ºå¾ˆéš¾ç”¨ä¸¥è°¨çš„æ–¹å¼æ¥ä¸ºè¿™ä¸€ç‚¹è¾©æŠ¤ã€‚

RMï¼šLLMsæ˜¯åœ¨ä»€ä¹ˆæ—¶å€™èƒ½å¤Ÿâ€œç†è§£â€ï¼ˆunderstandsï¼‰çš„ï¼Ÿ

ANï¼šâ€œç†è§£â€æ˜¯é€æ­¥å®ç°çš„ï¼Œä¸æ˜¯ä¸€è¹´è€Œå°±ã€‚ä¾‹å¦‚ï¼Œéšç€LLMsçš„å‘å±•ï¼Œæˆ‘ä»¬æœ‰äº†GPT-2ã€GPT-3ã€ChatGPTï¼Œæˆ‘è§‰å¾—å®ƒä»¬çš„ç†è§£æ°´å¹³ä¸æ–­æå‡â€”â€”ç›´åˆ°è®©æˆ‘ç›¸å½“è‡ªä¿¡åœ°è¯´ï¼ŒLLMsåœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œçš„ç¡®â€œç†è§£â€äº†è¿™ä¸ªä¸–ç•Œã€‚
2

æœ‰é£é™©ä½†æ¦‚ç‡å°ï¼ŒAIç­ç»è®ºâ‰ˆå¤–æ˜Ÿäººç­ç»è®º
RMï¼šå¦‚æœå¤§å®¶éƒ½è®¤åŒLLMså…·å¤‡â€œç†è§£â€ï¼ˆunderstandsï¼‰èƒ½åŠ›ï¼Œé‚£ä¹ˆå…³äºäººå·¥æ™ºèƒ½çš„äº‰è®ºä¼¼ä¹å¯ä»¥å½’ç»“ä¸ºåƒä½ è¿™æ ·çš„ä¹è§‚ä¸»ä¹‰è€…ï¼Œæ¯”å¦‚æ›´å…³æ³¨æŠ€æœ¯å½“å‰å…·å¤‡çš„èƒ½åŠ›ã€‚ç›¸å¯¹åœ°ï¼Œæœ«æ—¥è®ºè€…åˆ™æ›´å…³æ³¨æˆ‘ä»¬æ‰€è§è¯çš„äººå·¥æ™ºèƒ½æŒ‡æ•°çº§è¿›æ­¥å¯¹æœªæ¥å¯èƒ½é€ æˆçš„å½±å“ã€‚ä½ è®¤ä¸ºæœ«æ—¥è®ºè€…çš„æ¨è®ºåˆç†å—ï¼Ÿ

ANï¼šæˆ‘ä¸åŒæ„è¿™ä¸ªæè¿°ï¼Œå› ä¸ºè®¸å¤šä¹è§‚ä¸»ä¹‰è€…ä¹Ÿåœ¨å±•æœ›å‡ åå¹´åäººå·¥æ™ºèƒ½æ„å»ºçš„ç¾å¥½ä¸–ç•Œã€‚å…¶å®æ¶‰åŠâ€œäººå·¥æ™ºèƒ½ç­ç»äººç±»â€è¯é¢˜æ—¶ï¼Œå’Œæˆ‘äº¤è°ˆè¿‡çš„äººä»¬å¯¹æ­¤çš„æ‹…å¿§ä¼¼ä¹éå¸¸æ¨¡ç³Šï¼Œè€Œä¸”æ²¡äººèƒ½ç¡®åˆ‡åœ°è®²å‡ºâ€œäººå·¥æ™ºèƒ½å°†å¦‚ä½•å¯¼è‡´å…¨äººç±»ç­äº¡â€ã€‚

æˆ‘æ— æ³•è¯æ˜äººå·¥æ™ºèƒ½ä¸ä¼šå¯¼è‡´äººç±»ç­äº¡ï¼Œæ­£å¦‚æˆ‘ä¹Ÿæ— æ³•è¯æ˜åœ°çƒå‘å‡ºçš„æ— çº¿ç”µæ³¢ä¼šå¼•æ¥å¤–æ˜Ÿäººå¹¶æ¶ˆç­äººç±»ä¸€æ ·ã€‚ä½†æˆ‘ä¸ä¼šè¿‡åº¦æ‹…å¿ƒæ— çº¿ç”µæ³¢å¯¼è‡´äººç±»ç­ç»ï¼Œå°±åƒæˆ‘ä¹Ÿçœ‹ä¸åˆ°äººå·¥æ™ºèƒ½å¯èƒ½å¯¼è‡´äººç±»ç­ç»ä¸€æ ·ã€‚

RMï¼šç„¶è€Œï¼Œæœ‰ä¸€äº›å¾·é«˜æœ›é‡çš„ç§‘å­¦å®¶è®¤ä¸ºäººå·¥æ™ºèƒ½å¯¼è‡´ç­ç»çš„é£é™©æ˜¯å­˜åœ¨çš„ã€‚æˆ‘æƒ³é—®çš„æ˜¯ï¼Œä½œä¸ºäººç±»ï¼Œæˆ‘ä»¬è¯¥å¦‚ä½•ç¡®ä¿äººå·¥æ™ºèƒ½çš„å‘å±•ä¸ä¼šå¯¼è‡´äººç±»ç­ç»ï¼Ÿ

ANï¼šæ— çº¿ç”µä¿¡å·å¼•æ¥å¤–æ˜Ÿäººå¹¶ç­ç»å…¨äººç±»çš„å¯èƒ½æ€§ç¡®å®éé›¶ï¼Œä½†è¿™ä¸ªå‡ ç‡å¦‚æ­¤ä¹‹å°ï¼Œä»¥è‡³äºæˆ‘ä»¬ä¸åº”è¯¥ä¸ºäº†é˜²èŒƒè¿™ç§å¾®ä¹å…¶å¾®çš„å±é™©è€Œæµªè´¹å¤§é‡èµ„æºã€‚æˆ‘çœ‹åˆ°çš„æ˜¯ï¼Œæˆ‘ä»¬æ­£å¯¹å‡ ä¹ä¸ºé›¶çš„é£é™©ï¼ŒæŠ•å…¥å·¨å¤§åˆ°ä¸æˆæ¯”ä¾‹çš„èµ„æºã€‚

RMï¼šæ‰€ä»¥ä»ç›‘ç®¡çš„è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬éœ€è¦å“ªäº›æªæ–½ï¼Œå¦‚æœæœ‰çš„è¯ï¼Ÿ

ANï¼šæˆ‘ä»¬éœ€è¦å¥½ç›‘ç®¡ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬ç”¨äººå·¥æ™ºèƒ½æ„å»ºå…³é”®å‹åº”ç”¨ç¨‹åºæ—¶ï¼Œç¡®ä¿å®ƒä»¬æœ¬èº«å®‰å…¨ï¼Œå¹¶ä¿æŠ¤æ¶ˆè´¹è€…çš„ç›‘ç®¡æ˜¯ç»å¯¹å¿…è¦çš„ã€‚ä½†æˆ‘çœ‹åˆ°çš„å´æ˜¯å¾ˆå¤šç³Ÿç³•çš„ç›‘ç®¡ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ›´å¤šè¿™æ ·çš„ç›‘ç®¡ã€‚

RMï¼šç®€å•æ¥è¯´ï¼Œâ€œå¥½ç›‘ç®¡â€å’Œâ€œåç›‘ç®¡â€æ˜¯ä»€ä¹ˆï¼Ÿ

ANï¼šå¦‚æœæœ‰äººåœ¨æ„å»ºåŒ»ç–—ã€é‡‘èæ ¸ç®—æˆ–è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒä»¬æ˜¯å®‰å…¨çš„ï¼Œæ— åè§çš„ã€‚é‡‡å–åˆ†å±‚é£é™©ç®¡ç†æ–¹æ³•â€”â€”æ€è€ƒåº”ç”¨è½¯ä»¶çš„å®é™…é£é™©ï¼Œå¹¶å¯¹å¯èƒ½å‡ºç°çš„ä¸è‰¯ç»“æœè¿›è¡Œç›‘ç®¡â€”â€”è¿™å°†æ˜¯â€œå¥½ç›‘ç®¡â€ã€‚

ä½†å¯¹æˆ‘æ¥è¯´ï¼ŒåƒLLMså…·æœ‰â€œç³»ç»Ÿæ€§é£é™©â€çš„è¯´æ³•æ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚æ¯”å¦‚ï¼Œä¸€äº›æ”¿åºœåªå£°ç§°LLMså­˜åœ¨æ›´å¤§é£é™©ï¼Œä½†æ˜¯äººä»¬ä¹Ÿå¯ä»¥ç”¨å…¶ä»–å°å‹æˆ–å¤§å‹çš„è¯­è¨€æ¨¡å‹æ¥æ„å»ºå…·æœ‰æ½œåœ¨å±é™©çš„åŒ»ç–—è®¾å¤‡ã€‚åŒæ ·ï¼Œä¸è®ºæ˜¯å°æ¨¡å‹è¿˜æ˜¯å¤§æ¨¡å‹ï¼Œéƒ½å¯èƒ½ä¼šè¢«ç”¨æ¥æ•£æ’­è™šå‡ä¿¡æ¯ã€‚

å› æ­¤ï¼Œæ¨¡å‹çš„å¤§å°å¹¶ä¸æ˜¯è¡¡é‡é£é™©çš„æœ‰æ•ˆæ ‡å‡†ã€‚æ›´åˆç†çš„è¡¡é‡æ–¹å¼åº”å½“æ˜¯ï¼šåº”ç”¨ç¨‹åºçš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿä¾‹å¦‚ï¼ŒåŒ»ç–—åº”ç”¨æœ¬èº«é£é™©å°±æ›´é«˜ã€‚å¦ä¸€ä¸ªè¡¡é‡æ ‡å‡†æ˜¯åº”ç”¨ç¨‹åºçš„å½±å“èŒƒå›´ã€‚å¦‚æœæ˜¯ä¸€ä¸ªç¤¾äº¤åª’ä½“å¹³å°æ‹¥æœ‰äº¿ä¸‡ç”¨æˆ·ï¼Œé‚£ä¹ˆï¼Œå®ƒä¼ æ’­è™šå‡ä¿¡æ¯çš„é£é™©æ˜¾ç„¶è¦æ¯”åªæœ‰ç™¾åç”¨æˆ·çš„å°è®ºå›é«˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹å¤§å‹ç§‘æŠ€å…¬å¸å®æ–½æ›´ä¸¥æ ¼çš„ç›‘ç®¡ã€‚

è¿™æ ·çš„åšæ³•ä¸æ˜¯æ²¡æœ‰å…ˆä¾‹ã€‚ä¾‹å¦‚ï¼Œç¾å›½åŠ³å·¥éƒ¨OSHA-å·¥ä½œå®‰å…¨ä¸å¥åº·æ³•è§„å¯¹å¤§å‹é›‡ä¸»çš„è¦æ±‚å°±æ¯”å¯¹å°å‹é›‡ä¸»çš„è¦æ±‚å¤šï¼Œè¿™ç§å¹³è¡¡äº†å·¥äººä¿æŠ¤å’Œå°ä¼ä¸šè´Ÿæ‹…çš„åšæ³•å€¼å¾—å€Ÿé‰´ã€‚
3

Open AIä»¬çš„â€œè‡ªæ„¿æ‰¿è¯ºâ€å½¢åŒè™šè®¾
RMï¼šå»å¹´åæœˆï¼Œç™½å®«å‘å¸ƒäº†æ—¨åœ¨åŠ å¼ºäººå·¥æ™ºèƒ½æ”¿åºœç›‘ç®¡çš„è¡Œæ”¿ä»¤ã€‚è¿™æ˜¯å¦èµ°å¾—å¤ªè¿œäº†ï¼Ÿ

ANï¼šæˆ‘è®¤ä¸ºæˆ‘ä»¬å¯èƒ½èµ°é”™äº†æ–¹å‘ã€‚å¦‚æœæˆ‘ä»¬èƒ½åœ¨å®ªæ³•ä¸­ç¡®ç«‹â€”â€”é’ˆå¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•çš„é™åˆ¶åˆ°æ­¤ä¸ºæ­¢ï¼Œä¸ä¼šå†è¿›ä¸€æ­¥ã€‚æˆ‘æˆ–è®¸è¿˜èƒ½æ¥å—ã€‚ä½†å½“å‰çš„æƒ…å†µæ˜¯ï¼Œå„ç§æ”¿åºœéƒ¨é—¨è¢«æŒ‡æ´¾å»æƒ³è±¡å‡ºæ›´å¤šäººå·¥æ™ºèƒ½å‘å±•çš„éšœç¢ã€‚æˆ‘è®¤ä¸ºè¿™å°†å¯¼è‡´æˆ‘ä»¬èµ°ä¸Šæ‰¼æ€åˆ›æ–°ã€å»ºç«‹æå…·åç«äº‰æ€§ç›‘ç®¡çš„é“è·¯ã€‚

RMï¼šæˆ‘ä»¬ç›®å‰æ‰€äº†è§£çš„åªæœ‰å¤§çº²ï¼Œä½†ä¸çŸ¥é“å°†æ¥ä¸‹æ¥çš„å…·ä½“å®æ–½ï¼Ÿä¾‹å¦‚ï¼Œå¦‚æœå…¬å¸å¼€å‘ä»»ä½•å¯èƒ½å¯¹å›½å®¶å®‰å…¨æ„æˆé£é™©çš„åŸºç¡€æ¨¡å‹ï¼Œåº”é€šçŸ¥è”é‚¦æ”¿åºœï¼Œä¸”å¿…é¡»å…±äº«æ‰€æœ‰çº¢é˜Ÿå®‰å…¨æµ‹è¯•ç»“æœã€‚æˆ‘ä»¬ä¸çŸ¥é“ä¸Šè¿°åŸºç¡€æ¨¡å‹ã€å…±äº«ä¿¡æ¯çš„å…·ä½“ç•Œå®šæ ‡å‡†ã€‚

ANï¼šç°åœ¨å¾ˆå¤šæ¸¸è¯´è€…å¿™ç€ç»™æ”¿åºœå¡‘é€ ç«‹åœºã€‚ç™½å®«çš„è¡Œæ”¿ä»¤æœ€åˆè®¾å®šçš„å¼ºåˆ¶é€šçŸ¥é—¨æ§›æ˜¯è®¡ç®—æ‰€éœ€ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯è¡¡é‡æ¨¡å‹é£é™©çš„éå¸¸ç®€å•åŒ–çš„æ–¹æ³•ã€‚ï¼ˆé€‚é“æ³¨ï¼šè¡Œæ”¿ä»¤è¦æ±‚â€”â€”å¦‚æœæ–°çš„äººå·¥æ™ºèƒ½æ¨¡å‹è®¡ç®—é‡è¶…è¿‡ä¸€å®šé˜ˆå€¼ï¼Œå¼€å‘è¯¥æ¨¡å‹çš„å…¬å¸è¦åœ¨è®­ç»ƒç³»ç»Ÿæ—¶é€šçŸ¥è”é‚¦æ”¿åºœã€‚ï¼‰

æˆ‘ä»¬çŸ¥é“ï¼Œä»Šå¤©çš„è¶…çº§è®¡ç®—æœºå¯èƒ½å°±æ˜¯æ˜å¤©çš„æ™ºèƒ½æ‰‹è¡¨ã€‚éšç€åˆåˆ›å…¬å¸è§„æ¨¡æ‰©å¤§ï¼Œæ›´å¤šçš„è®¡ç®—èµ„æºå˜å¾—æ™®éå¯ç”¨ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„ç»„ç»‡ä¼šè§¦åŠè¿™ä¸ªé—¨æ§›ã€‚å°†è®¡ç®—èµ„æºè®¾ä¸ºé—¨æ§›ï¼Œå°±åƒè¯´ä¸€ä¸ªç”¨è¶…è¿‡50ç“¦ç”µçš„è®¾å¤‡æ¯”ç”¨10ç“¦çš„è®¾å¤‡å…·æœ‰æ›´å¤§ç³»ç»Ÿæ€§å±é™©ä¸€æ ·ï¼šè™½ç„¶è¿™å¯èƒ½æ˜¯çœŸçš„ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•ç²—æš´çš„é£é™©è¡¡é‡æ–¹å¼ã€‚

RMï¼šå¦‚æœæˆ‘ä»¬ä¸ä»¥è®¡ç®—é‡ä½œä¸ºé—¨æ§›ï¼Œé‚£ä¹ˆæ›´å¥½çš„é£é™©è¡¡é‡æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿ

ANï¼šå½“æˆ‘ä»¬è§‚å¯Ÿåº”ç”¨ç¨‹åºæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç†è§£åˆ°åº•ä»€ä¹ˆæ„å‘³ç€å®‰å…¨ï¼Œä»€ä¹ˆæ„å‘³ç€å±é™©ï¼Œå¹¶æ®æ­¤è¿›è¡Œé€‚å½“çš„ç›‘ç®¡ã€‚å› ä¸ºæŠ€æœ¯çš„ç”¨é€”å¹¿æ³›ï¼Œå¦‚æœå¯¹æŠ€æœ¯å±‚é¢è¿›è¡Œç›‘ç®¡ï¼Œåªä¼šå‡ç¼“æŠ€æœ¯è¿›æ­¥çš„é€Ÿåº¦ã€‚

æœ€æ ¹æœ¬çš„é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬æ˜¯å¦è®¤ä¸ºä¸–ç•Œä¼šå› ä¸ºâ€œæ™ºæ…§â€å¢åŠ è€Œå˜å¾—æ›´å¥½ï¼Ÿâ€œæ™ºæ…§â€åŒ…æ‹¬â€œäººç±»æ™ºæ…§â€å’Œâ€œäººå·¥æ™ºèƒ½â€ã€‚

æ¯«æ— ç–‘é—®ï¼Œâ€œæ™ºæ…§â€å¯ä»¥è¢«ç”¨äºä¸è‰¯ç”¨é€”ã€‚ä½†ç»è¿‡å¤šä¸ªä¸–çºªçš„å‘å±•ï¼Œéšç€äººç±»æ›´èªæ˜å’Œæ•™è‚²æ™®åŠåŒ–å¢åŠ ï¼Œç¤¾ä¼šå¾—ä»¥è¿›æ­¥ã€‚æˆ‘ç›¸ä¿¡ï¼Œä¸–ç•Œå¦‚æœæ‹¥æœ‰æ›´å¤šçš„â€œæ™ºæ…§â€ï¼Œæ— è®ºæ˜¯äººç±»çš„è¿˜æ˜¯äººå·¥çš„ï¼Œéƒ½å°†å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°è§£å†³é—®é¢˜ã€‚å› æ­¤ï¼Œä»…ä»…å› ä¸ºâ€œæ™ºæ…§â€å¯èƒ½è¢«ç”¨äºæŸäº›ä¸è‰¯ç›®çš„ï¼Œå°±è®¾ç½®ç›‘ç®¡éšœç¢ï¼Œæˆ‘è®¤ä¸ºè¿™ä¼šè®©ç¤¾ä¼šå€’é€€ã€‚

RMï¼šæˆ‘ä»¬å¦‚ä½•ä¿éšœä¸å°†â€œæ™ºæ…§â€ç”¨äºä¸è‰¯ç”¨é€”ï¼Ÿ

ANï¼šå½“ç„¶åº”è¯¥è¯†åˆ«â€œæ™ºæ…§â€çš„ä¸è‰¯ç”¨é€”ï¼Œå¹¶å¯¹å…¶è¿›è¡Œé˜²èŒƒã€‚å¦‚æœæˆ‘ä»¬æ€è€ƒäººå·¥æ™ºèƒ½ç­ç»ä¸»ä¹‰çš„è§‚ç‚¹ï¼Œä¼šå‘ç°å…¶æè¿°çš„åœºæ™¯æ˜¯å¦‚æ­¤æ¨¡ç³Šå’Œå¤¸å¼ ï¼Œæˆ‘è®¤ä¸ºè¿™å¹¶ä¸ç°å®ï¼Œä¹Ÿå¾ˆéš¾é˜²èŒƒã€‚

ä½†ç°å®ä¸­ç¡®å®å­˜åœ¨ä¸€äº›é£é™©ï¼Œä¾‹å¦‚æˆ‘ä»¬ä¸å¸Œæœ›ä¿é™©æ ¸ç®—åº”ç”¨å¸¦æœ‰åè§ï¼Œé‚£ä¹ˆå°±å¯ä»¥åˆ¶å®šå®¡è®¡ä¿é™©æ ¸ç®—åº”ç”¨çš„è§„åˆ™ï¼Œå¹¶ä¸”è¯„ä¼°åº”ç”¨çš„å…¬å¹³æ€§â€”â€”è¿™ä¼šæ˜¯ä¸€ä¸ªç§¯æçš„å˜åŒ–ã€‚è‡³äºé‚£äº›ä¼šå½±å“å¤§é‡ç”¨æˆ·çš„ç¤¾äº¤åª’ä½“æˆ–èŠå¤©æœºå™¨äººå…¬å¸ï¼Œåˆ™å­˜åœ¨è™šå‡ä¿¡æ¯æˆ–åè§çš„é£é™©ã€‚æ­¤æ—¶ï¼Œæˆ‘è®¤ä¸ºï¼Œé€æ˜åº¦å°±æ˜¯æœ‰æ„ä¹‰çš„ã€‚

æ€»è€Œè¨€ä¹‹ï¼Œå¦‚æœæˆ‘ä»¬å¯¹å½±å“å·¨å¤§ã€é£é™©æ›´é«˜çš„ä¼ä¸šå®æ–½ç›‘ç®¡ï¼Œæˆ‘ä»¬å°±ä¸åº”è¯¥åŒæ—¶ä¹Ÿé˜»ç¢å°å‹åˆåˆ›ä¼ä¸šçš„å‘å±•ï¼Œè¿™ä¼šå‰¥å¤ºå®ƒä»¬æˆé•¿ä¸ºå¤§å‹ä¼ä¸šçš„æœºä¼šã€‚

RMï¼šäººå·¥æ™ºèƒ½ç”Ÿæˆçš„å‡è§†é¢‘ç­‰å†…å®¹å¯èƒ½ä¼šæ¿€å¢ï¼Œæ”¿åºœè¯¥ç®¡å—ï¼Ÿ

ANï¼šè¿™æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„é—®é¢˜ã€‚æˆ‘è®¤ä¸ºåŠ æ°´å°å¯èƒ½æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚ä»Šå¹´7æœˆï¼ŒåŒ…æ‹¬Googleã€Metaå’ŒOpenAIåœ¨å†…çš„å…¬å¸å‘ç™½å®«æ‰¿è¯ºï¼Œåœ¨å¼€å‘äººå·¥æ™ºèƒ½æ—¶éµå®ˆä¸‰ä¸ªåŸºæœ¬åŸåˆ™ï¼šå®‰å…¨ã€ä¿éšœå’Œä¿¡ä»»ã€‚ä½†å¦‚æœä½ ä»”ç»†é˜…è¯»è¿™äº›æ‰¿è¯ºï¼Œæˆ‘è®¤ä¸ºé™¤äº†â€œåŠ æ°´å°â€ä¹‹å¤–ï¼Œå…¶ä»–éƒ½æ˜¯ç©ºè¯ã€‚å› ä¸ºå…¬å¸å®Œå…¨å¯ä»¥é˜³å¥‰é˜´è¿ã€‚

ä¸ºäº†é˜²èŒƒé€šè¿‡è§†é¢‘æˆ–æ–‡æœ¬â€”â€”å°¤å…¶æ˜¯æ–‡æœ¬â€”â€”å¤§è§„æ¨¡æ•£æ’­è™šå‡ä¿¡æ¯çš„é£é™©ï¼Œæˆ‘è®¤ä¸ºåŠ æ°´å°æ˜¯çœŸæ­£åº”è¯¥è€ƒè™‘çš„æªæ–½ã€‚å¾ˆä¸å¹¸ï¼Œè‡ªä»ä¸Šè¿°çš„ç™½å®«æ‰¿è¯ºä»¥æ¥ï¼Œæˆ‘çœ‹åˆ°ä¸€äº›å…¬å¸åœ¨ç»™æ–‡æœ¬å†…å®¹åŠ æ°´å°ä¸Šåè€Œå€’é€€äº†ã€‚æ‰€ä»¥ï¼Œæˆ‘è§‰å¾—å°†è‡ªæ„¿æ‰¿è¯ºä½œä¸ºä¸€ç§ç›‘ç®¡æ‰‹æ®µæ˜¯å¤±è´¥çš„ã€‚

4

ç³Ÿç³•çš„ç›‘ç®¡ä¸å¦‚æ²¡æœ‰ç›‘ç®¡
RMï¼šæˆ‘ä»¬æˆ–è®¸èƒ½æ„Ÿå—åˆ°ï¼Œå‘¼åæ›´ä¸¥æ ¼ç›‘ç®¡çš„å£°éŸ³æ›´å“äº®ã€‚é‚£ä¹ˆï¼Œä½ èƒ½å¦æ„Ÿåˆ°è‡ªå·±çš„ç«‹åœºæ˜¯å­¤å•çš„ï¼Ÿ

ANï¼šå…¶å®ï¼Œæˆ‘éå¸¸å¸Œæœ›æ”¿åºœèƒ½ç§¯æå‡ºå‡»ï¼Œåˆ¶å®šå‡ºä¸€äº›å¥½è§„åˆ™ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬ç°åœ¨æ‰€çœ‹åˆ°çš„ä¸è‰¯ç›‘ç®¡ææ¡ˆã€‚æ‰€ä»¥ï¼Œæˆ‘ä¸ä¸»å¼ æ”¾ä»»ä¸ç®¡ã€‚ä½†åœ¨ç³Ÿç³•çš„ç›‘ç®¡å’Œæ²¡æœ‰ç›‘ç®¡ä¹‹é—´ï¼Œæˆ‘å®æ„¿æ²¡æœ‰ç›‘ç®¡ã€‚ç„¶è€Œï¼Œä¸€äº›åŒ…æ‹¬å·¨å¤´ç§‘æŠ€å…¬å¸åœ¨å†…çš„å¼ºå¤§åŠ¿åŠ›è¿‡åˆ†å¤¸å¤§äººå·¥æ™ºèƒ½çš„é£é™©ã€‚è¯šç„¶ï¼Œå¤§å…¬å¸æ›´æƒ³é¿å¼€å’Œå¼€æºäººå·¥æ™ºèƒ½çš„ç«äº‰ã€‚ä»–ä»¬çš„ç­–ç•¥å¾€å¾€æ˜¯å¤¸å¤§ææƒ§ï¼Œç„¶åå®æ–½è§„åˆ™æ¥å»¶ç¼“åˆ›æ–°ï¼Œæ”¾æ…¢å¼€æºçš„æ­¥ä¼ã€‚

æˆ‘çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šæ‰€å±•ç°çš„ï¼Œè¯æ˜äº†å¼€æºè½¯ä»¶å’Œä¸€äº›ä¸“æœ‰æ¨¡å‹çš„ç«äº‰éå¸¸æ¿€çƒˆâ€”â€”å°½ç®¡å®ƒä»¬å¯èƒ½ä¸æ˜¯æœ€ä¼˜ç§€çš„ï¼Œä½†æ¯”ä¸€äº›æ—©æœŸç‰ˆæœ¬å·²ç»å¾ˆä¸é”™äº†ã€‚è€Œå¯¹äºä¸€äº›å…¬å¸æ¥è¯´ï¼Œå¦‚æœæ²¡æœ‰å¼€æºè½¯ä»¶çš„ç«äº‰ï¼Œé‚£å°†ä¼šç•…é€šæ— é˜»ã€‚

RMï¼šä½ èƒ½æŒ‡å‡ºä¸€äº›åœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½å¨èƒè®ºè¿°çš„å…¬å¸å—ï¼Ÿ

ANï¼šä½ çŸ¥é“ä»–ä»¬éƒ½æœ‰è°ã€‚å¤šå®¶å…¬å¸éƒ½åœ¨å¼ºè°ƒå¨èƒè®ºè¿°ã€‚å¯¹äºé‚£äº›æ›´æ„¿æ„é¿å…å’Œå¼€æºç«äº‰çš„å¤§å‹ä¼ä¸šæ¥è¯´ï¼Œè¿™æ˜¯ä¸€ç§åŠ¨åŠ›ï¼›å¯¹äºä¸€äº›éè¥åˆ©ç»„ç»‡æ¥è¯´ï¼Œå¤¸å¤§ææƒ§ï¼Œåˆ¶é€ å¹»è±¡ï¼Œç„¶åç­¹é›†èµ„é‡‘æ¥å¯¹æŠ—ä»–ä»¬è‡ªå·±åˆ¶é€ çš„å¹»è±¡ï¼Œè¿™ä¹Ÿæ˜¯æŒ¯å¥‹äººå¿ƒçš„ï¼›ä¸€äº›ä¸ªäººå¯ä»¥å¤¸å¤§ææƒ§å¾—åˆ°æ›´å¤šå…³æ³¨å’Œæ›´é«˜æ¼”è®²è´¹ã€‚ä¸è¿‡ï¼Œæˆ‘è®¤ä¸ºæœ‰ä¸€äº›äººæ˜¯çœŸè¯šçš„â€”â€”ä»–ä»¬å¯èƒ½è¯¯å…¥æ­§é€”ï¼Œä½†ç¡®å®æ˜¯çœŸè¯šçš„â€”â€”ä½†åœ¨è¿™ä¹‹ä¸Šï¼Œå­˜åœ¨ä¸ºäº†æŸäº›åˆ©ç›Šè€Œå¤¸å¤§ææƒ§çš„åŠ¨æœºã€‚

æˆ‘ä¸è®¤ä¸ºæˆ‘æ˜¯å”¯ä¸€è¿™ä¹ˆæƒ³çš„äººã€‚Bill Gurleyï¼ˆBenchmarkçš„åˆä¼™äººï¼‰å¯¹ç›‘ç®¡æ•è·çš„æ€è€ƒéå¸¸æ·±åˆ»ã€‚ä»–åœ¨YouTubeçš„ä¸€æ¬¡æ¼”è®²éå¸¸ç²¾å½©ï¼Œå‡†ç¡®åœ°é¢„æµ‹äº†ç°åœ¨æ­£åœ¨å‘ç”Ÿçš„è®¸å¤šç›‘ç®¡æ•è·è¡ŒåŠ¨ã€‚Yann LeCunä¹Ÿåœ¨è¿™ä¸ªé—®é¢˜ä¸Šå‘è¡¨äº†çœ‹æ³•ã€‚æˆ‘è®¤ä¸ºå®é™…ä¸Šæœ‰å¾ˆå¤šäººå¯¹æ­¤æœ‰éå¸¸æ·±æ€ç†Ÿè™‘çš„çœ‹æ³•ã€‚ï¼ˆé€‚é“ï¼šç›‘ç®¡æ•è·â€”â€”ç›‘ç®¡è€… è¢« ç›‘ç®¡å¯¹è±¡ç”¨å„ç§æ–¹æ³•â€œæ•è·â€ï¼Œæ²¦ä¸ºå°‘æ•°åˆ©ç›Šé›†å›¢çš„å·¥å…·äººã€‚ï¼‰

RMï¼šåªæ˜¯ä¼¼ä¹å¦ä¸€æ–¹å£°éŸ³æ›´å“äº®ã€‚

ANï¼šå¦ç™½è¯´ï¼Œä½ ä»¬æ˜¯åª’ä½“ï¼Œæ‰€ä»¥ä½ ä»¬å¯ä»¥æ‰©å¤§å£°éŸ³ã€‚è¡€è…¥çš„å¤´æ¡æ€»æ˜¯æ›´å—æ¬¢è¿ï¼Œææƒ§ä¹Ÿæ˜¯ä¸€æ ·ã€‚å½“å¾ˆå¤šäººç­¾ç½²å£°æ˜ï¼Œç§°äººå·¥æ™ºèƒ½åƒæ ¸æ­¦å™¨ä¸€æ ·å±é™©æ—¶ï¼Œåª’ä½“å°±ä¼šç»™äºˆäº†å¤§é‡å…³æ³¨ã€‚è€Œå½“æ›´ç†æ€§çš„å£°æ˜å‡ºç°æ—¶â€”â€”ä¾‹å¦‚ï¼ŒMozillaè¡¨ç¤ºå¼€æºæ˜¯ç¡®ä¿äººå·¥æ™ºèƒ½å®‰å…¨çš„å¥½æ–¹æ³•â€”â€”å‡ ä¹æ²¡æœ‰åª’ä½“æŠ¥é“ã€‚

æˆ‘è®¤ä¸ºäººå·¥æ™ºèƒ½å®‰å…¨ä¸­å¿ƒï¼ˆCAISï¼‰çš„æªæ–½éå¸¸å·®åŠ²ã€‚å› ä¸ºå¾ˆå¤šç›‘ç®¡è€…ä¸ç†è§£äººå·¥æ™ºèƒ½ï¼Œå½“é‚£ä¸ªå°†äººå·¥æ™ºèƒ½å’Œæ ¸æ­¦å™¨ç›¸æå¹¶è®ºçš„å£°æ˜ï¼Œå°†è¯¯å¯¼ä¿¡æ¯éå¸¸æ¸…æ¥šåœ°ä¼ æ’­å¼€æ¥ï¼Œå°±æ‰­æ›²äº†ç›‘ç®¡è€…çš„æ€è€ƒã€‚æˆ‘å·²ç»çœ‹åˆ°äº†è¯¥å£°æ˜å¯¹ç¾å›½æ”¿åºœçš„å½±å“ã€‚ç„¶è€Œï¼Œå°†äººå·¥æ™ºèƒ½ç±»æ¯”ä¸ºæ ¸æ­¦å™¨éå¸¸è’è°¬ã€‚äººå·¥æ™ºèƒ½å¯ä»¥å¸®åŠ©æˆ‘ä»¬åšå‡ºæ›´å¥½çš„å†³ç­–ï¼›è€Œæ ¸æ­¦å™¨å´èƒ½æ‘§æ¯åŸå¸‚ã€‚è¿™äºŒè€…èƒ½æœ‰ä»€ä¹ˆå…³è”ï¼Ÿ

å¦‚ä»Šï¼Œæ›´å¤šå›½å®¶å·²ç»æ„è¯†åˆ°äº†ç›‘ç®¡æ•è·çš„é£é™©ï¼Œå› ä¸ºå½“å‰è®¸å¤šç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„é¡¶å°–äººæ‰éƒ½é›†ä¸­åœ¨ç¾å›½ã€‚å¦‚æœå‡ºå°çš„è§„åˆ™é˜»ç¢äº†å¼€æºæ¨¡å‹çš„ä¼ æ’­ï¼ŒçŒœçŒœè°ä¼šè½åï¼Ÿå‡ ä¹æ˜¯æ‰€æœ‰é™¤äº†ç¾å›½ä¹‹å¤–çš„å›½å®¶ã€‚

å½“ç„¶ç¾å›½çš„ä¸€éƒ¨åˆ†åŠ›é‡ä¹Ÿå¸Œæœ›çœ‹åˆ°è¿™ç§å±€é¢ï¼Œå› ä¸ºä»–ä»¬è®¤ä¸ºç¾å›½çš„ç«äº‰å¯¹æ‰‹é€šè¿‡å¼€æºè½¯ä»¶è·å¾—äº†å¥½å¤„ã€‚æ²¡æœ‰äººå¸Œæœ›çœ‹åˆ°äººå·¥æ™ºèƒ½è¢«ç”¨äºä¸ä¹‰ä¹‹æˆ˜ï¼Œä½†å‡ç¼“å…¨çƒåˆ›æ–°çš„è¿›ç¨‹ã€è®©å…¨ä¸–ç•Œçš„æ™ºæ…§å’Œå†³ç­–è´¨é‡ä¸‹é™çš„ä»£ä»·å¤ªé«˜ã€‚

æˆ‘å¸Œæœ›æ¬§æ´²çš„ç›‘ç®¡è€…ä¹Ÿèƒ½æ„è¯†åˆ°è¿™ä¸€ç‚¹ã€‚å¦ç™½è¯´ï¼Œå¦‚æœæˆ‘ä»¬æ”¾æ…¢äº†å¼€æºçš„æ­¥ä¼ï¼Œé‚£ä¹ˆè°å°†è¢«é—å¼ƒåœ¨åé¢ï¼Ÿ
5

è½¯ä»¶å±‚é¢ï¼Œå„å›½åŒç­‰å—é™
RMï¼šåœ¨é˜…è¯»æå¼€å¤çš„ã€Šäººå·¥æ™ºèƒ½è¶…çº§å¤§å›½ï¼ˆAI Superpowersï¼‰ã€‹ï¼ˆ2018ï¼‰ä¸€ä¹¦åï¼Œæˆ‘æ›¾ç¡®ä¿¡ä¸­å›½å°†å¼•é¢†äººå·¥æ™ºèƒ½å‘å±•çš„æµªæ½®ã€‚ä½†è¿™ä¼¼ä¹å¹¶æ²¡æœ‰å‘ç”Ÿã€‚ä½ è®¤ä¸ºåŸå› ä½•åœ¨ï¼Ÿ

ANï¼šæå¼€å¤è®ºè¿°äº†ä¸­å›½çš„æ•°æ®è·å–ä¼˜åŠ¿ï¼Œä½†æ•°æ®æ˜¯éå¸¸å‚ç›´åŒ–çš„ä¸œè¥¿ã€‚ä¾‹å¦‚ï¼ŒGoogleæœ‰å¤§é‡ç½‘ç»œæœç´¢æ•°æ®ï¼Œä½†è¿™äº›æ•°æ®å¯¹ç‰©æµã€æ™ºèƒ½æ‰‹æœºåˆ¶é€ æˆ–è¯ç‰©ç ”å‘ä¸äº§ç”Ÿç›´æ¥ä½œç”¨ã€‚

ä¸åŒå›½å®¶åœ¨ä¸åŒå‚ç›´è¡Œä¸šæ‹¥æœ‰çš„æ•°æ®å¯ä»¥åˆ›é€ å„è‡ªçš„ä¼˜åŠ¿ã€‚ä¸­å›½åœ¨ç›‘æ§æŠ€æœ¯æ–¹é¢æš‚æ—¶é¢†å…ˆç¾å›½ï¼Œè¿™æ˜¯å¾—ç›Šäºä¸­å›½æ•°å­—æ”¯ä»˜çš„å…´èµ·ã€‚ä½†æˆ‘è®¤ä¸ºï¼Œç¾å›½åœ¨å…¶å¼ºåŠ¿é¢†åŸŸæ‹¥æœ‰å¤§é‡æ•°æ®å¹¶æŒæœ‰ä¼˜åŠ¿ï¼Œæ¯”å¦‚ç½‘ç»œæœç´¢ã€è¯ç‰©ç ”å‘ã€åˆ¶è¯ç­‰è¡Œä¸šã€‚

æŠ€æœ¯å‘å±•æ˜¯é˜¶æ®µæ€§çš„ï¼Œä¸­å›½åªæ˜¯é”™è¿‡äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æµªæ½®çš„èµ·ç‚¹ã€‚è®¸å¤šæ—©æœŸï¼Œç”šè‡³ç°åœ¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å·¥ä½œæ˜¯ç”±ä¸¤ä¸ªå›¢é˜Ÿå®Œæˆçš„ï¼šæˆ‘çš„å‰å›¢é˜ŸGoogle Brainå’ŒOpenAIï¼ŒäºŒè€…éƒ½åœ¨ç¡…è°·ã€‚æœ‰æ—¶è¿™äº›å›¢é˜Ÿæˆå‘˜ç¦»å¼€åä¼šå¦èµ·ç‚‰ç¶ï¼Œè¿™å°±æ˜¯å¦‚ä»Šç”Ÿæˆå¼äººå·¥æ™ºèƒ½äººæ‰åœ¨ç¡…è°·äº‘é›†çš„åŸå› ã€‚å°½ç®¡è‹±å›½ã€åŠ æ‹¿å¤§ã€ä¸­å›½ä¹Ÿæœ‰äººæ‰èšé›†ï¼Œä½†å®é™…ä¸Šé›†ä¸­åº¦è¿œä¸å¦‚ç¡…è°·ã€‚å³ä¾¿æ˜¯è¥¿é›…å›¾ã€çº½çº¦ï¼Œä¹Ÿæ¯”ä¸ä¸Šç¡…è°·ã€‚

RMï¼šä¸­å›½å¯¹äººå·¥æ™ºèƒ½çš„ç›‘ç®¡æ€åº¦ç›¸å½“æ¿€è¿›â€”â€”ä»»ä½•å…¬å¸æƒ³è¦å…¬å¼€å‘å¸ƒLLMéƒ½å¿…é¡»è·å¾—æ‰¹å‡†ï¼Œä¸”å½“å±€è¦å®¡æŸ¥å…¶è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†ã€‚ä½ è®¤ä¸ºè¿™ä¼šæ‰¼æ€åˆ›æ–°å—ï¼Ÿ

ANï¼šæˆ‘ä¸æ˜¯è¿™æ–¹é¢çš„ä¸“å®¶ã€‚æˆ‘è®¤ä¸ºåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šï¼Œè§„å®šå…·ä½“å¦‚ä½•è®©å®æ–½ä¼šå½±å“å…¶æ˜¯å¦ä¼šæ‰¼æ€åˆ›æ–°ã€‚

RMï¼šæœ€è¿‘ï¼Œè…¾è®¯å’Œé˜¿é‡Œå·´å·´éƒ½åœ¨è¡¨è¾¾ä»–ä»¬å› ç¼ºå°‘Nvidia èŠ¯ç‰‡è€Œåœ¨äººå·¥æ™ºèƒ½å‘å±•ä¸Šå—é™ã€‚ä½ å¦‚ä½•çœ‹å¾…ç¾å›½çš„åšæ³•ï¼Ÿ

ANï¼šç¾å›½å¯¹èŠ¯ç‰‡çš„å‡ºå£æ§åˆ¶æ— ç–‘å¯¹ä¸­å›½çš„äººå·¥æ™ºèƒ½å‘å±•äº§ç”Ÿäº†å®è´¨æ€§å½±å“ã€‚ä½†æˆ‘æ³¨æ„åˆ°ä¸­å›½åœ¨æ²¡æœ‰å…ˆè¿›Nvidia å’ŒAMDèŠ¯ç‰‡çš„æƒ…å†µä¸‹ï¼Œç”¨ä½åŠŸè€—èŠ¯ç‰‡åœ¨LLMsæ¨ç†ä¸Šåšäº†å¤§é‡åˆ›æ–°ã€‚è‡³å°‘ç°åœ¨ï¼Œå‡ºå£ç®¡åˆ¶è¿˜å­˜åœ¨è¶³å¤Ÿå¤šçš„æ¼æ´ï¼Œæˆ‘è®¤ä¸ºä¸­å›½å…¬å¸ä¹Ÿåœ¨å°è¯•å¯»æ‰¾æµ·å¤–è®¡ç®—èµ„æºã€‚æœªæ¥ä¸€åˆ‡å¦‚ä½•å‘å±•è¿˜æœ‰å¾…è§‚å¯Ÿã€‚

RMï¼šä½ è®¤ä¸ºç¾å›½åº”è¯¥è¿™æ ·åšå—â€”â€”åŸºæœ¬ä¸Šæ˜¯è¯•å›¾å‰Šå¼±ä¸­å›½çš„äººå·¥æ™ºèƒ½äº§ä¸šï¼Ÿ

ANï¼šæˆ‘å¯¹è¿™ä¸ªé—®é¢˜çš„æƒ…æ„Ÿæœ‰äº›å¤æ‚ï¼Œæˆ‘ä¸æ˜¯åœ°ç¼˜æ”¿æ²»ä¸“å®¶ã€‚ä¸è¿‡æ˜¾è€Œæ˜“è§ï¼Œç¾å›½æ­£è¯•å›¾ç›‘ç®¡åŸºç¡€æ¨¡å‹â€”â€”æœ‰ä¸€ä¸ªæ´¾ç³»å½±å“äº†ç™½å®«çš„è¡Œæ”¿ä»¤ï¼Œå› ä¸ºä»–ä»¬æ‹…å¿ƒç¾å›½çš„å¯¹æ‰‹ä¼šåˆ©ç”¨å¼€æºè½¯ä»¶ã€‚æ‰€ä»¥ï¼Œåœ¨è½¯ä»¶å±‚é¢ï¼Œæˆ‘è®¤ä¸ºç¾å›½è‡ªå·±å—åˆ°çš„é™åˆ¶å’Œå…¶ä»–å›½å®¶ä¸€æ ·å¤šï¼Œè¿™æ˜¯ä¸€ä¸ªé”™è¯¯ã€‚è‡³äºç¡¬ä»¶ï¼Œæˆ‘äº†è§£å¾—ä¸å¤šã€‚

RMï¼šå¬èµ·æ¥ï¼Œä½ è®¤ä¸ºä¸­å›½çš„ä¼ä¸šå¯ä»¥æ‰¾åˆ°æ–¹æ³•ç»•è¿‡èŠ¯ç‰‡é™åˆ¶ã€‚

ANï¼šæ˜¯çš„ï¼Œæˆ‘å·²ç»è§åˆ°å¾ˆå¤šåˆ›æ–°ï¼Œå°½ç®¡æœ‰èŠ¯ç‰‡é™åˆ¶ï¼Œä¹Ÿèƒ½å¤Ÿå®Œæˆå·¥ä½œã€‚

## è‹±æ–‡

Ryan McMorrow DECEMBER 19 2023


Just over a decade ago, Andrew Ng was part of a Google Brain project that showed the power of deep learning technology.

For three days, Ngâ€™s team fed a neural network millions of unlabelled images from YouTube videos. After training, the system could identify features such as cats in images it had not encountered before â€” even though it had not been explicitly taught how. This research became known informally as the â€œCat Paperâ€ and laid the groundwork for future advances in artificial intelligence.Â 

At around the same time, from his perch as a Stanford professor, Ng pushed into online teaching, making a course on machine learning available to anyone with an internet connection. Its popularity, along with that of other â€œmassive open online coursesâ€, or Moocs, at the time, led Ng and his colleague Daphne Koller to found online education provider Coursera.Â 

A few years later Ng moved to Baidu, the Chinese search giant, to help deepen its autonomous driving and AI research efforts. Today he invests in and builds an array of AI start-ups, runs one of his own, and continues to teach courses on AI.Â 

When the FT visited Ngâ€™s Palo Alto offices, he pulled out a laptop and turned off its WiFi to demonstrate how an open-source large language model (LLM) from French AI start-up Mistral can run without needing to send data to the cloud.Â 

Tech ExchangeÂ 

The FTâ€™s top reporters and commentators hold monthly conversations with the worldâ€™s most thought-provoking technology leaders, innovators and academics, to discuss the future of the digital world and the role of Big Tech companies in shaping it. The dialogues are in-depth and detailed, focusing on the way technology groups, consumers and authorities will interactÂ to solve global problems and provide new services. Read them all here

â€œThe model is saved on my hard disc and then itâ€™s using the GPU and CPU [graphics processing unit and central processing unit] on my laptop to just run inference,â€ he said. When it was given the question of what a reporter should ask Andrew Ng about AI, the background it delivered on Ng and his work looked like the kind of response one would get from ChatGPT, OpenAIâ€™s hit LLM-powered chatbot.Â Â 

An advocate of open-source AI development, Ng has emerged as an outspoken critic of some government efforts to regulate it. Here he speaks about AIâ€™s current capabilities, why warnings of extinction risk are overblown, and what good regulation would look like.

Ryan McMorrow: When do you use these open-source AI models?Â 

Andrew Ng: I run multiple models on my laptop â€” Mistral, Llama, Zefa. And I use ChatGPT quite often. But for privacy-sensitive things that I donâ€™t want to send to a cloud provider, I would tend to use them all on my laptop. Like brainstorming on really confidential projects, or helping me with writing that contains sensitive financial figures. Open-source language models are actually getting pretty good.

RM: Yet many tech companies are desperate for Nvidiaâ€™s chips to run AI. Why should they bother if the Mistral model on your laptop can handle it?

AN: This is a smaller language model: itâ€™s only 7bn parameters, and not competitive with GPT-4 for sophisticated reasoning tasks. GPT-4 is much better at answering complex questions. But for simple brainstorming, simple facts, this is fine. And itâ€™s sometimes pretty fast as well, as you see.


Hot chip: sales of Nvidiaâ€™s processors have soared, as big tech companies favour them for developing AI systems Â© I-Hwa Cheng/Bloomberg
Training a model from scratch, though, is completely unfeasible on my laptop â€” that still needs tens of millions of dollars. Training that uses the massive amount of compute and inference [problem solving with fresh data] on the very large models would be beyond what I could do on my laptop.

Actually, I have done inference on a 70bn parameter model on my laptop and it is annoyingly slow. And so if you have a 175bn-parameter model, which is the size of GPT-3, that would not be something I could do on my laptop. Inference on the large models still needs data centre-level resources.Â 

An open-source model can get used to build many kinds of app. If you regulate that core technology, youâ€™re slowing everything down, and probably without making anything safer

Open-source softwareâ€™s getting easy enough for most people to just install it and use it now. And itâ€™s not that Iâ€™m obsessed about regulation â€” but if some of the regulators have their way, itâ€™d be much harder to let open-source models like this keep up.

RM: How would regulations disrupt open-source?

AN: Some proposals, for instance, have reporting or even licensing requirements for LLMs. And while the big tech companies have the bandwidth to deal with complex compliance, smaller businesses just donâ€™t.

Just as an example, Iâ€™m picturing a midsize company that wants to release an open-source model. If a lawyer in that company starts saying, â€œHey, just so you know, there could be all sorts of liability if you do this,â€ then I think fewer companies would take that liability risk. Whatever we put more regulatory burdens on, thatâ€™s what weâ€™ll see less of.

An open-source model is a general purpose technology: it can get used to build a healthcare app, a customer service app, a financial services app, and on and on. So if you regulate that core technology, youâ€™re slowing everything down, and probably without making anything meaningfully safer.

RM: Framing any discussion of regulation has to be a sense of what AI is capable of â€” of where AI stands today. And in June you had a conversation with Geoffrey Hinton [a computer scientist who has warned of the dangers of AI] about whether AI models understand the world and it seemed like you were not fully convinced that they do. Whatâ€™s your current view?

AN: I think they do. One of the problems with terms like â€œunderstandsâ€ or, going even further, â€œconsciousâ€ or â€œsentientâ€, is that they are not well defined. So thereâ€™s no widely accepted test for when something understands something, as opposed to merely looks like it understands something.Â 

But from the scientific evidence Iâ€™ve seen, AI models do build models of the world. And so if an AI has a model of the world, then Iâ€™m inclined to believe it does understand the world. But thatâ€™s applying my own sense of what the word â€œunderstandingâ€ means.Â 

RM: What do you mean by a model of the world?

AN: If you have a world model, then you have a sense of how the world works and can make predictions about how it may evolve under different scenarios. And thereâ€™s been scientific evidence showing that LLMs, when trained on a lot of data, do build a world model.Â 

What the researchers did was basically to take an LLM and train it to model moves in the board game Othello â€” C4, D5, B3, whatever. And then, after Othello-GPT, as they called it, had learned to predict the next move, they asked, â€œHas this system learned a model of the board, and has it learned a model of the rules of the game of Othello?â€. And when they probed it, the insides of the neural network appeared to have built a model of the board in order to predict the next moves. Because of that experiment, and others like it, I believe LLMs are building, internally, some model of the world, and so I feel comfortable saying they do understand the world.


Learn the rules, grasp the world: researchers who trained a large language model to predict moves in Othello found that it had built a (digital) model of the board to do so Â© Alamy
RM: Do you think they have consciousness as well?

AN: I might skirt the consciousness question, because it feels to me like a philosophical question rather than a scientific one. I think philosophers say that, as people, out of politeness, we all assume other people are conscious â€” but how do you know if I am conscious? Maybe Iâ€™m just a zombie, and I just act like a conscious being. So I think thereâ€™s no test for consciousness, which is why itâ€™s a philosophical rather than a scientific problem.

RM: Leaving aside consciousness, do you think an LLM can think for itself?

AN: I donâ€™t know what that phrase means. Iâ€™m inclined to say yes, but, because of the lack of a clear definition of what it means to think, itâ€™s hard to say. Can a relay switch in my ceiling lamp think for itself? There is a whole spectrum [that includes] this kind of relay switch thinking for itselfâ€‰.â€‰.â€‰.â€‰Iâ€™d be inclined to say it does, but I think Iâ€™d have a hard time defending that in a rigorous way.

RM: When did LLMs get to the point of understanding?

AN: Understanding comes in gradual degrees. I donâ€™t think itâ€™s a binary criterion. But as LLMs grew, and we had GPT-2, GPT3, ChatGPT, I feel like they were demonstrating increasing levels of understanding â€” to the point where I feel quite comfortable saying that, to some extent, LLMs understand the world today. 

RM: If itâ€™s agreed that LLMs have the capacity to understand, the debate on AI seems to come down to optimists like yourself, who focus on what the technology is currently capable of, and doomers, who focus on projecting what the exponential advances weâ€™re seeing will mean for the future. Do you think thereâ€™s any reason to extrapolate like they do? 

AN: I donâ€™t agree with that characterisation. A lot of the AI optimists are looking decades into the future at the amazing things we can build with AI. When I think about the AI human extinction scenarios, when I speak with people who say theyâ€™re concerned about this, their concerns seem very vague. And no one seems to be able to articulate exactly how AI could kill us all.

We are spending vastly disproportionate resources against a risk that is almost zero

I canâ€™t prove that AI wonâ€™t kill us all, which is akin to proving a negative, any more than I can prove that radio waves being emitted from Earth wonâ€™t allow aliens to find us and wipe us out. But I am not overly concerned about our radio waves leading to our extinction, and in a similar way I donâ€™t see how AI could lead to human extinction.

RM: Yet there are well-regarded scientists who think there is some chance of that. I guess the question is: how should we as humans make sure that AIâ€™s development doesnâ€™t lead to our extinction?

AN: There is also some chance that is absolutely non-zero of our radio signals causing aliens to find us and wipe us all out. But the chance is so small that we should not waste disproportionate resources to defend against that danger. And what Iâ€™m seeing is that we are spending vastly disproportionate resources against a risk that is almost zero.

RM: So in terms of regulation, what, if any, do we need?

AN: We need good regulation. When we use AI to build critical applications, regulations to ensure that theyâ€™re safe and protect consumers is absolutely needed. But what Iâ€™m seeing is a lot of bad AI regulation, and we donâ€™t need more of that.


Things not to come: Ng argues that worries about AI posing an extinction risk are overblown â€” on a par with fears that radio waves from Earth could attract hostile extraterrestrials Â© Alamy
RM: What is good and bad regulation in a nutshell?

AN: If someone is building a healthcare or underwriting or self-driving car application, we want it to be safe and unbiased. Taking a tiered risk approach â€” thinking through what are the actual risks with applications and regulating against the bad outcome â€” would be good regulation.

But there is this phrase going around that LLMs represent a systemic risk, and that makes no sense to me. Some governments are just asserting that LLMs represent a bigger risk, but people can build dangerous medical devices with a small language model or with a large language model. And people can build systems for misinformation with a small or large language model. So the size of the language model is a very weak measure for risk.Â 

A better measure would be: what is the nature of the application? Because healthcare applications will be more risky, for example. Another metric would be the reach of the application. If a social media company has 100mn users, the risk of disinformation is much bigger than a message board with just 100 users. And consequently we would regulate big tech companies more.Â 

This is a common practice. For example, the USâ€™s Osha [Occupational Safety and Health Administration] laws put more requirements on big employers than on small employers. That balances protecting workers with not overly burdening small businesses.Â Â Â 

RM: In October, the White House issued an executive order intended to increase government oversight of AI. Has it gone too far?

AN: I think that weâ€™ve taken a dangerous step. If we were to enshrine in the constitution that barriers to AI technology development will stop here and go no further, maybe itâ€™s OK. But with various government agencies tasked with dreaming up additional hurdles for AI development, I think weâ€™re on the path to stifling innovation and putting in place very anti-competitive regulations.Â 

RM: From what we have so far, itâ€™s a broad outline â€” do we know how theyâ€™re going to implement it? For example, companies developing foundation models considered a risk to national security must notify the government and share the results of safety tests. Do we know what counts as a foundation model and how people are supposed to share information?Â 

AN: At this moment there are certainly lots of lobbyists who are very busy helping the government shape its perspective. The White House EO took its initial cut [on the threshold for mandatory notification] as the amount of computation needed, which I think is a very naive way to measure the risk of a model.

Having more intelligence in the world, be it human or artificial, will help all of us better solve problems

We know that todayâ€™s supercomputer is tomorrowâ€™s smartwatch, so as start-ups scale and as more compute becomes pervasive, weâ€™ll see more and more organisations run up against this threshold. Setting a compute threshold makes as much sense to me as saying that a device that uses more than 50 Watts is systematically more dangerous than a device that uses only 10W: while it may be true, it is a very naive way to measure risk.

RM: What would be a better way to measure risk? If weâ€™re not using compute as the threshold?

AN: When we look at applications, we can understand what it means for something to be safe or dangerous and can regulate it properly there. The problem with regulating the technology layer is that, because the technology is used for so many things, regulating it just slows down technological progress.Â 

At the heart of it is this question: do we think the world is better off with more or less intelligence? And it is true that intelligence now comprises both human intelligence and artificial intelligence. And it is absolutely true that intelligence can be used for nefarious purposes. But over many centuries, society has developed as humans have become better educated and smarter. I think that having more intelligence in the world, be it human or artificial, will help all of us better solve problems. So throwing up regulatory barriers against the rise of intelligence, just because it could be used for some nefarious purposes, I think would set back society.

RM: How do we safeguard against the possibility of using intelligence for nefarious purposes?

AN: I think we should absolutely identify the nefarious uses of intelligence and safeguard against them. If we look at AI extinctionism, its scenarios are so vague and fantastical that I donâ€™t think theyâ€™re realistic. And theyâ€™re also hard to defend against.Â 

But there are realistic scenarios. We want underwriting software to be fair. Putting in place regulations to make sure that underwriting software is audited and measured for fairness â€” that would be a welcome change. And with social media or even chatbot companies that reach large numbers of users, and there is a risk of misinformation or bias, transparency makes sense to me. But if we regulate businesses that impact a lot of users and therefore carry more risk, we shouldnâ€™t also slow down the small start-ups and deny them a shot at becoming bigger businesses that then should rightfully become more heavily scrutinised.

RM: What about the potential proliferation of fake videos and other content created by AI? Is that something for the government to regulate?

AN: Thatâ€™s a tricky one. I think watermarking could be a good idea. There was a White House voluntary commitment to AI [in July, when companies including Google, Meta and OpenAI pledged not to compromise safety, security and public trust in developing the technology]. And if you read those commitments carefully, I think all of them were fluff â€” meaning that companies could say they [were complying while] doing nothing differently from what they were already doing â€” except for one, which was the commitment to watermark generated content.

To guard against large-scale misinformation through videos or text â€” text is the important one to pay attention to â€” I think watermarking is something we should seriously consider. Unfortunately, since that White House voluntary commitment, Iâ€™ve seen companies step back from watermarking text content. So I feel that the voluntary commitment approach is failing as a regulatory approach.

RM: It seems like the voices urging tighter regulation are a lot louder and maybe more numerous than those arguing the opposite. Do you feel like youâ€™re alone in pushing for the hands-off approach?Â 

AN: Actually I would love for governments to be hands on and to write good regulation, as opposed to the bad regulatory proposals weâ€™re seeing, so Iâ€™m not advocating hands off. But between bad regulation and no regulation, Iâ€™d rather see no regulation.

Unfortunately, there are massive forces, including some very large companies, that I think are overhyping the risks of AI. Big companies would frankly rather not have to compete with open-source AI. And unfortunately the recipe is to hype up fears, and then try to put in place regulations to slow down innovation and slow down open-source.

Look at what we just did on my laptop: open-source software is surprisingly competitive with some of the proprietary [models] â€” not with the best, but with some of the earlier versions. And itâ€™d be very convenient for some companies not to have to compete with this.

RM: Can you name some companies that are pushing this AI threat narrative?

I see no reason to make an analogy between AI and nuclear weapons. It is an insane analogy

AN: You can imagine [who they are]. Multiple companies are overhyping the threat narrative. For large businesses that would rather not compete with open-source, there is an incentive. For some non-profits, there is an incentive to hype up fears, hype up phantoms, and then raise funding to fight the phantoms they themselves conjured. And there are also some individuals who are definitely commanding more attention and larger speaker fees because of fear that they are helping to hype up. I think there are a few people who are sincere â€” mistaken but sincere â€” but on top of that there are significant financial incentives for one or multiple parties to hype up fear.

I donâ€™t think Iâ€™m alone in feeling this way. Bill Gurley [general partner at venture capital firm Benchmark] has been very thoughtful about regulatory capture. He gave a talk thatâ€™s on YouTube, a fantastic talk, he accurately predicted a lot of regulatory capture moves that are being played out now. [Computer scientist] Yann LeCun has been speaking about this as well. I think there are actually quite a few people with a very thoughtful perspective on this.

RM: It just seems like the other side is louder.Â 

AN: And frankly, youâ€™re the media. So you can help. â€œIf it bleeds, it leadsâ€, and similarly for fear as well. When lots of people signed [the Center for AI Safety statement] saying AI is dangerous like nuclear weapons, the media covered that. When there have been much more sensible statements â€” for example, Mozilla saying that open source is a great way to ensure AI safety â€” almost none of the media cover that.Â  


West is best: tech investor Bill Gurley has said that Silicon Valleyâ€™s success in innovation owes a lot to its being so far from regulators in Washington, DC Â© David Paul Morris/Bloomberg
I think that Cais move was one of the most unfortunate things, because a lot of regulators are confused about AI. The statement that when you think about AI, you should think about nuclear weapons â€” that message, that misleading message, came through loud and clear, and distorted the thinking among the regulators. I saw the impact it had in DC.

I see no reason to make an analogy between AI and nuclear weapons. It is an insane analogy. One brings more intelligence and helps make better decisions, and the other blows up cities. What have these two things to do with each other?Â 

The risk of regulatory capture is starting to dawn on more nations, because a lot of generative AI talent is concentrated in the US today and one of the best ways to make sure that cutting-edge technology is widely disseminated is open source. If regulations come up that hamper dissemination of open source, guess who will be left behind? Pretty much everyone other than the US.

There are forces in the US that would like to see that happen because of the perceived risk that the USâ€™s adversaries are benefiting from open source. But while no one wants to see AI used to wage an unjust war, I think the price of slowing down global innovation, of letting there be less intelligence and poorer decision-making all around the world, is too high a price to pay. I hope the European regulators figure this out, too, because, frankly, who will be left behind if we slow down open source?

RM: After reading Kai-Fu Leeâ€™s book AI Superpowers, which came out in 2018, I was convinced that China would be the one leading the way on AI development. But that doesnâ€™t really seem to have happened. Why do you think that is?Â 

AN: Kai-Fu made an argument about Chinaâ€™s access to data. But data is very verticalised â€” data is not a single, featureless glob of things that you just want more of. For example, while Google has tons of web search data, that data by itself is not very useful for logistics, or smartphone manufacturing, or drug discovery.

And different countries will have data in different verticals that they can leverage to their own advantage. China is cyclically ahead of the US in its application of surveillance technology, and also because of the rise of digital payments in China. But I think that the US, in the industries where it is strong, has lots of its own data, and has assets to maintain its strengths â€” sectors like web search, drug discovery, pharmaceuticals.Â 

US export controls on semiconductor chips are definitely having a meaningful impact on Chinaâ€™s AI development

Technology comes in bursts. China just missed the beginnings of the generative AI wave. A lot of the early generative AI work â€” and even now, frankly â€” was done by two teams: Google Brain, my former team, and OpenAI, which both happened to be here in Silicon Valley. And sometimes people leave these teams and start other companies, which is why at this moment I see a very heavy concentration of deep tech talent in generative AI in Silicon Valley and nowhere else. There are pockets of talent, in the UK, in Canada, in China, but itâ€™s actually very concentrated just in Silicon Valley. Even Seattle, say, and New York have much less generative AI talent than Silicon Valley.

RM: Beijing has been taking a pretty aggressive approach with regulating AI. Any LLM that a company wants to release to the public has to be approved, and the authorities want to look at what data sets it has been trained on. Do you think thatâ€™s going to stifle innovation?Â 

AN: Iâ€™m not an expert on this. I think the implementation of these regulations will have a big impact on how much they are or are not stifling.Â 

RM: Recently, Tencent and Alibaba have been talking about their lack of access to Nvidia chips as a possible constraint on their development of AI. What do you think about the USâ€™s approach?

AN: US export controls on semiconductor chips are definitely having a meaningful impact on Chinaâ€™s AI development. Iâ€™m seeing a lot of innovation in China on getting things done without access to the advanced Nvidia and AMD chips â€” innovation on how to do inference on LLMs using lower power chips. And at least right now, the export controls have enough loopholes that I think companies in China are sometimes trying to find their compute overseas. So how it all shakes out remains to be seen.Â 

RM: Do you think the US should be doing this â€” essentially trying to hobble their industry?

AN: I have very mixed feelings about it, but Iâ€™m not an expert in geopolitics. But one thing that is clear is that the US is trying to regulate foundation models â€” there is definitely a faction in Washington, DC, that is influencing things like the White House executive order because of fears about the USâ€™s adversaries getting access to open-source software.

For the software layer, I think the US is hobbling itself as much as anyone else. And thatâ€™s a mistake. The hardware Iâ€™m less of an expert on.

RM: It sounds like you think that Chinese companies can find ways around these chip constraints.

AN: Iâ€™ve seen a lot of innovation to get things done despite the chip constraints, right.Â 
